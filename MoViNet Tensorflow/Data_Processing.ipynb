{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q remotezip tqdm opencv-python==4.5.2.52 opencv-python-headless==4.5.2.52 tf-models-official"
      ],
      "metadata": {
        "id": "6PAlykEWEgtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ],
      "metadata": {
        "id": "nc4AI8quEaed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import random\n",
        "import pathlib\n",
        "import itertools\n",
        "import collections\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import remotezip as rz\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dD6FGiwMEZ5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xS7rev3dEjuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Data"
      ],
      "metadata": {
        "id": "O0GjXwYtD9-r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag_NfCoYC3WK"
      },
      "outputs": [],
      "source": [
        "def get_class(fname):\n",
        "    \"\"\" \n",
        "    Retrieve the name of the class given a filename.\n",
        "\n",
        "    Args:\n",
        "      fname: Name of the file in the UCF101 dataset.\n",
        "\n",
        "    Returns:\n",
        "      Class that the file belongs to.\n",
        "    \"\"\"\n",
        "    return fname.split('/')[4]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_files_per_class(files):\n",
        "    \"\"\" \n",
        "    Retrieve the files that belong to each class.\n",
        "\n",
        "    Args:\n",
        "      files: List of files in the dataset.\n",
        "\n",
        "    Returns:\n",
        "      Dictionary of class names (key) and files (values). \n",
        "    \"\"\"\n",
        "    files_for_class = collections.defaultdict(list)\n",
        "    for fname in files:\n",
        "        class_name = get_class(fname)\n",
        "        files_for_class[class_name].append(fname)\n",
        "    return files_for_class"
      ],
      "metadata": {
        "id": "N_JR-wdKDgmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 10\n",
        "FILES_PER_CLASS = 25"
      ],
      "metadata": {
        "id": "gc0DQwGhDjUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"drive/MyDrive/Data/*/*/*.mp4\")\n",
        "files.sort()\n",
        "files[:10]"
      ],
      "metadata": {
        "id": "6hXdD1_oDjO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_for_class = get_files_per_class(files)\n",
        "classes = list(files_for_class.keys())"
      ],
      "metadata": {
        "id": "Ogyc0VN9DqJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Num classes:', len(classes))\n",
        "print('Num videos for class[0]:', len(files_for_class[classes[0]]))"
      ],
      "metadata": {
        "id": "wlwLxWDADtfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_subset_of_classes(files_for_class, classes, files_per_class):\n",
        "    \"\"\" \n",
        "    Create a dictionary with the class name and a subset of the files in that class.\n",
        "\n",
        "    Args:\n",
        "      files_for_class: Dictionary of class names (key) and files (values).\n",
        "      classes: List of classes.\n",
        "      files_per_class: Number of files per class of interest.\n",
        "\n",
        "    Returns:\n",
        "      Dictionary with class as key and list of specified number of video files in that class.\n",
        "    \"\"\"\n",
        "    files_subset = dict()\n",
        "\n",
        "    for class_name in classes:\n",
        "        class_files = files_for_class[class_name]\n",
        "        files_subset[class_name] = class_files[:files_per_class]\n",
        "\n",
        "    return files_subset"
      ],
      "metadata": {
        "id": "PdP73th-DxyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_subset = select_subset_of_classes(files_for_class, classes[:NUM_CLASSES], FILES_PER_CLASS)\n",
        "list(files_subset.keys())"
      ],
      "metadata": {
        "id": "Yix5qnumD0o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Frames from Each Video"
      ],
      "metadata": {
        "id": "uXnn9Yb-D1PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_frames(frame, output_size):\n",
        "    \"\"\"\n",
        "    Pad and resize an image from a video.\n",
        "\n",
        "    Args:\n",
        "      frame: Image that needs to resized and padded. \n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      Formatted frame with padding of specified output size.\n",
        "    \"\"\"\n",
        "    frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
        "    frame = tf.image.resize_with_pad(frame, *output_size)\n",
        "    return frame"
      ],
      "metadata": {
        "id": "vItPGzxiD7fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_frame(frame):\n",
        "    \"\"\"\n",
        "    Performs data augmentation on a single frame.\n",
        "    \n",
        "    Args:\n",
        "        frame : A single frame from the video.\n",
        "        \n",
        "    Return:\n",
        "        The augmented frame.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Randomly flip the frame horizontally\n",
        "    if random.random() < 0.5:\n",
        "        frame = cv2.flip(frame, 1)\n",
        "\n",
        "    # Randomly rotate the frame\n",
        "    angle = random.uniform(-10, 10)\n",
        "    height, width = frame.shape[:2]\n",
        "    rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
        "    frame = cv2.warpAffine(frame, rotation_matrix, (width, height))\n",
        "\n",
        "    # Randomly crop the frame\n",
        "    crop_size = int(min(frame.shape[:2]) * random.uniform(0.8, 1.0))\n",
        "    x = random.randint(0, frame.shape[1] - crop_size)\n",
        "    y = random.randint(0, frame.shape[0] - crop_size)\n",
        "    frame = frame[y:y+crop_size, x:x+crop_size]\n",
        "\n",
        "    return frame"
      ],
      "metadata": {
        "id": "u0U8FwVbEHBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def frames_from_video_file(video_path, n_frames, output_size=(224, 224), frame_step=20, augment=False):\n",
        "    \"\"\"\n",
        "    Creates frames from each video files present for each class.\n",
        "    \n",
        "    Args:\n",
        "        video_path : File path to the video.\n",
        "        n_frames : Number of frames to be created per video file.\n",
        "        output_size : Pixel size of the output frame image.\n",
        "        frame_step : The step size between consecutive frames.\n",
        "        augment : Whether to perform data augmentation.\n",
        "        \n",
        "    Return:\n",
        "        An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
        "    \"\"\"\n",
        "    \n",
        "    # Read each video frame by frame\n",
        "    result = []\n",
        "    src = cv2.VideoCapture(str(video_path))\n",
        "\n",
        "    video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "\n",
        "    need_length = 1 + (n_frames - 1) + frame_step\n",
        "\n",
        "    if need_length > video_length:\n",
        "        start = 0\n",
        "    else:\n",
        "        max_start = video_length - need_length\n",
        "        start = random.randint(0, max_start + 1)\n",
        "\n",
        "    src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "\n",
        "    # ret is a boolean indicating whether the read was successful, frame is the image itself.\n",
        "    ret, frame = src.read()\n",
        "    if augment:\n",
        "        frame = augment_frame(frame)\n",
        "    result.append(format_frames(frame, output_size))\n",
        "\n",
        "    for _ in range(n_frames - 1):\n",
        "        for _ in range(frame_step):\n",
        "            ret, frame = src.read()\n",
        "        if ret:\n",
        "            if augment:\n",
        "                frame = augment_frame(frame)\n",
        "            frame = format_frames(frame, output_size)\n",
        "            result.append(frame)\n",
        "        else:\n",
        "            result.append(np.zeros_like(result[0]))\n",
        "\n",
        "    src.release()\n",
        "    result = np.stack(result, axis=0)[..., [2, 1, 0]]\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "8mkF8vR3EJi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"drive/MyDrive/Data/Test/LungePose/LungePose_02.mp4\""
      ],
      "metadata": {
        "id": "SWrWcElgELW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_video = frames_from_video_file(video_path, n_frames = 16)\n",
        "sample_video.shape"
      ],
      "metadata": {
        "id": "2I4qczSzENfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_gif(images):\n",
        "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
        "  imageio.mimsave('./animation.gif', converted_images, fps=10)\n",
        "  return embed.embed_file('./animation.gif')"
      ],
      "metadata": {
        "id": "sLMbGne5EPFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_gif(sample_video)"
      ],
      "metadata": {
        "id": "e1uuRsD0ESn7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}